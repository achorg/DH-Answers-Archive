<?xml version="1.0" encoding="UTF-8"?>
<!-- generator="bbPress/1.0.2" -->
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Digital Humanities Questions &#38; Answers &#187; User Favorites: zachwhalen</title>
		<link><a href='http://digitalhumanities.org/answers/profile/zachwhalen'>zachwhalen</a></link>
		<description>Digital Humanities Questions &amp; Answers &#187; User Favorites: zachwhalen</description>
		<language>en-US</language>
		<pubDate>Mon, 02 May 2016 06:33:41 +0000</pubDate>
		<generator>http://bbpress.org/?v=1.0.2</generator>
		<textInput>
			<title><![CDATA[Search]]></title>
			<description><![CDATA[Search all topics from these forums.]]></description>
			<name>q</name>
			<link>http://digitalhumanities.org/answers/search.php</link>
		</textInput>
		<atom:link href="/DH-Answers-Archive/rss/profile/" rel="self" type="application/rss+xml" />

		<item>
			 
				<title>mkirschenbaum on "Best approaches for using DC fields to describe physical computing components?"</title>
						<link>http://digitalhumanities.org/answers/topic/best-approaches-for-using-dc-fields-to-describe-physical-computing-components#post-2097</link>
			<pubDate>Tue, 10 Sep 2013 13:11:09 +0000</pubDate>
			<dc:creator>mkirschenbaum</dc:creator>
			<guid isPermaLink="false">2097@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/zachwhalen'&#62;zachwhalen&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/best-approaches-for-using-dc-fields-to-describe-physical-computing-components#post-2095&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;/p&#62;
&#60;p&#62;Responded on Twitter, but for the archive of the question here: &#60;/p&#62;
&#60;p&#62;We used Dublin Core fields behind Omeka to catalog individual hardware components from some of MITH's vintage computers: &#60;/p&#62;
&#60;p&#62;&#60;a href=&#34;http://mith.umd.edu/vintage-computers/&#34; rel=&#34;nofollow&#34;&#62;http://mith.umd.edu/vintage-computers/&#60;/a&#62;
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Patrick Murray-John on "Best approaches for using DC fields to describe physical computing components?"</title>
						<link>http://digitalhumanities.org/answers/topic/best-approaches-for-using-dc-fields-to-describe-physical-computing-components#post-2096</link>
			<pubDate>Tue, 10 Sep 2013 12:33:08 +0000</pubDate>
			<dc:creator>Patrick Murray-John</dc:creator>
			<guid isPermaLink="false">2096@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;This reflects strength and weakness of both DC and Omeka itself. What an &#34;Item&#34; is is left completely up to you and your interpretation. That chains down to how to interpret the DC fields depending a bit on how you define an &#34;Item&#34;.&#60;/p&#62;
&#60;p&#62;In your case, it might be helpful to create item types. One could be &#34;Particular Component&#34; (i.e., yours) and one could be &#34;Component Type&#34; for the general class.&#60;/p&#62;
&#60;p&#62;I'd probably call Synertek the creator, and probably make &#34;Fabrication Place&#34; as item type metadata.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>zachwhalen on "Best approaches for using DC fields to describe physical computing components?"</title>
						<link>http://digitalhumanities.org/answers/topic/best-approaches-for-using-dc-fields-to-describe-physical-computing-components#post-2095</link>
			<pubDate>Mon, 09 Sep 2013 22:03:37 +0000</pubDate>
			<dc:creator>zachwhalen</dc:creator>
			<guid isPermaLink="false">2095@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Hi,&#60;/p&#62;
&#60;p&#62;I've got my students working on an assignment where we take apart old media devices, learn about their key components, and then create an Omeka exhibit about our device, using Neatline to trace each component in time and space. This part works pretty well, so far.&#60;/p&#62;
&#60;p&#62;For example, I'm taking apart an Atari VCS. The MOS 6507 CPU bears the MOS technologies logo so was probably (I've learned) manufactured at their plant in Norristown, PA. The TIA chip, on the other hand, has a Synertek logo which (I've learned) second-sourced many of the integrated circuits used by Atari. Even though Atari's TIA chip (the famous Stella) was originally fabricated by MOS in Pennsylvania, &#60;em&#62;mine&#60;/em&#62; was produce at Synertek in California. &#60;/p&#62;
&#60;p&#62;My problem is, I want to capture that kind of distinction in my record, but I'm not sure how to use Omeka's Dublin Core fields to describe everything that I find interesting about these chips, including those differences in production sites. My understanding of DC is pretty basic -- for example, does it make a distinction between &#34;The TIA Chip&#34; as a class of objects exhibiting uniform properties, vs. &#34;My TIA Chip&#34; which has a specific origin in time and place? &#60;/p&#62;
&#60;p&#62;In other words, is Synertek the &#34;creator&#34;, &#34;publisher&#34;, or &#34;source&#34;? And what does &#34;coverage&#34; mean?&#60;/p&#62;
&#60;p&#62;Am I over-thinking this? Are there better ontologies for this kind of archive?&#60;/p&#62;
&#60;p&#62;I welcome any and all suggestions. Thanks for your time.&#60;/p&#62;
&#60;p&#62;Zach
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Wally Grotophorst on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1166</link>
			<pubDate>Wed, 04 May 2011 22:34:37 +0000</pubDate>
			<dc:creator>Wally Grotophorst</dc:creator>
			<guid isPermaLink="false">1166@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;ABBYY FineReader is the engine in Devonthink Pro Office (Mac only).  ABBYY Finereader software (the application) ships with ScanSnap for Mac as well.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Ben Brumfield on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1164</link>
			<pubDate>Wed, 04 May 2011 12:47:35 +0000</pubDate>
			<dc:creator>Ben Brumfield</dc:creator>
			<guid isPermaLink="false">1164@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/jmhuculak'&#62;jmhuculak&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1161&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;/p&#62;
&#60;p&#62;Note that ABBYY FineReader is incorporated into other tools as well, including some of Adobe's PDF generators and the Internet Archive's book upload derivation software.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>jmhuculak on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1161</link>
			<pubDate>Wed, 04 May 2011 12:12:40 +0000</pubDate>
			<dc:creator>jmhuculak</dc:creator>
			<guid isPermaLink="false">1161@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I second the copyright concerns. &#60;/p&#62;
&#60;p&#62;I've worked for years digitizing periodicals, and as far as OCR goes, you can't find a better program than ABBYY FineReader Professional. You can only get it for Windows, so if you are using a mac, install bootcamp and run it from a Windows partition. (do not use the mac version, it is not powerful enough yet). &#60;/p&#62;
&#60;p&#62;The reason ABBYY is so good, is that it is spectacular recognizing small text. This trait alone will save you hours of correction. Also, it allows you to export to HTML, XML, text-under-image PDF, etc.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>laurie taylor on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1152</link>
			<pubDate>Sun, 01 May 2011 19:37:43 +0000</pubDate>
			<dc:creator>laurie taylor</dc:creator>
			<guid isPermaLink="false">1152@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Omeka's a great option for a more exhibit-style approach, but there are loads of other options if you're interested in partnering with a library.  As mentioned, Chronicling America is a great place to start. It's built from a major NEH + Library of Congress project, the National Digital Newspaper Program. For it,  pre-1923 papers are being digitized in massive numbers so if any of your grandfather's columns are pre-1923, then they might already be included in those projects which are done by state. If they're later, lots of states are currently grappling with how to preserve and make accessible more recent news, including born digital newspapers currently being published. &#60;/p&#62;
&#60;p&#62;With all of this work going on, the best option could be to partner with a library to digitize the full 35 year run for the full paper. Even if the library partner can't partner for the full project, they can probably help with the OCR process (running the columns during off-cycle times) if that's helpful. Partnering with a library also means they can benefit from integrating the columns in a full newspaper digital library and they can ensure preservation. Libraries can also help with any copyright questions for the full newspaper and/or individual columns.&#60;/p&#62;
&#60;p&#62;If dealing with the paper in print, be very careful if it's actually moldy because it can be a major health hazard (libraries digitize moldy papers with great caution - masks, hepa filters, special disposal to prevent contamination, etc). &#60;/p&#62;
&#60;p&#62;I'm happy to help in general if I can, and there could be a collaborative opportunity if you're grandfather's columns are from Florida or the Caribbean (I'm the technical director for the Florida Digital Newspaper Library and the Caribbean Newspaper Digital Library: &#60;a href=&#34;http://ufdc.ufl.edu/newspapers&#34; rel=&#34;nofollow&#34;&#62;http://ufdc.ufl.edu/newspapers&#60;/a&#62; and &#60;a href=&#34;http://dloc.com/cndl&#34; rel=&#34;nofollow&#34;&#62;http://dloc.com/cndl&#60;/a&#62; ). &#60;/p&#62;
&#60;p&#62;Laurie
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Wally Grotophorst on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1141</link>
			<pubDate>Sat, 23 Apr 2011 09:20:58 +0000</pubDate>
			<dc:creator>Wally Grotophorst</dc:creator>
			<guid isPermaLink="false">1141@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;What form are these columns in?  newspaper clippings? typed pages?
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Patrick Murray-John on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1140</link>
			<pubDate>Sat, 23 Apr 2011 08:10:30 +0000</pubDate>
			<dc:creator>Patrick Murray-John</dc:creator>
			<guid isPermaLink="false">1140@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Zach,&#60;/p&#62;
&#60;p&#62;When it comes to the transcription part, I'd add &#60;a href=&#34;http://scripto.org&#34;&#62;Scripto&#60;/a&#62; to the list of tools to evaluate.&#60;/p&#62;
&#60;p&#62;Patrick
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Ben Brumfield on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1138</link>
			<pubDate>Fri, 22 Apr 2011 21:45:33 +0000</pubDate>
			<dc:creator>Ben Brumfield</dc:creator>
			<guid isPermaLink="false">1138@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/zachwhalen'&#62;zachwhalen&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1136&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;/p&#62;
&#60;p&#62;If I were you and it was my family--and if some fairly naive assumptions about the obviousness of chronological organization and accessibility of the material hold--here's what I would do:&#60;/p&#62;
&#60;p&#62;0: Get my copyright ducks in a row -- find out who owns the copyrights to the columns.&#60;/p&#62;
&#60;p&#62;1: Scan the columns, being fairly careful to make sure that separate pages of the same column remain together and are differentiated from other columns.&#60;/p&#62;
&#60;p&#62;2: Upload the scans to the Internet Archive's Community Texts project, taking some care with the metadata so that the resulting pages are well organized on the Archive.org servers.  Part of the Internet Archive's derivation process involves OCR, so you'll end up with page images hosted (for free!), as well as searchable PDFs, DjVu files and eText formats.&#60;/p&#62;
&#60;p&#62;3: Move the derivative DjVu files to WikiSource, setting up a private instance of your own if the English-language community rules are too limiting.&#60;/p&#62;
&#60;p&#62;4: Enlist friends and family to correct and proofread the OCR using the built-in Wikisource ProofreadPage plugin.  This will track workflow, allow you to flag columns for review, and display how much of the collection has been reviewed.&#60;/p&#62;
&#60;p&#62;5: Use the built-in coolness of MediaWiki to do neat things with the column.  If you're using en.wikisource.org, you can place all the columns into a category and then use the &#34;Make a book&#34; feature to generate publish-on-demand collections of the columns.  (I've tried this with Wikipedia's cognate tool and was blown away by the quality and cost.)  If you're running your own private instance of wikisource, you can hack away with the MediaWiki toolset however you like -- annotating entries in-line using wikilinks, categorizing the columns by subject, mining the mark-up a la DBPedia, or whatever else you come up with.&#60;/p&#62;
&#60;p&#62;I'm sure that other folks will have their own suggestions, but this might be an easy way to leverage to existing tools and the communities that are built around them.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>mjgiarlo on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1137</link>
			<pubDate>Fri, 22 Apr 2011 19:55:08 +0000</pubDate>
			<dc:creator>mjgiarlo</dc:creator>
			<guid isPermaLink="false">1137@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Hi Zach,&#60;/p&#62;
&#60;p&#62;Neat project idea.&#60;/p&#62;
&#60;p&#62;I don't have any ready answers about digitization or OCR, but I would suggest adding Chronicling America to your list of software packages for displaying, housing, and searching your newspapers (though Omeka is a good choice too).  It's being developed by the Library of Congress as an open source application for delivery of historic newspapers.  Source code and docs are here:&#60;/p&#62;
&#60;p&#62;&#60;a href=&#34;http://sourceforge.net/apps/trac/loc-ndnp/&#34; rel=&#34;nofollow&#34;&#62;http://sourceforge.net/apps/trac/loc-ndnp/&#60;/a&#62;&#60;/p&#62;
&#60;p&#62;And you can see the latest version demonstrated here:&#60;/p&#62;
&#60;p&#62;&#60;a href=&#34;http://chroniclingamerica.loc.gov/beta/&#34; rel=&#34;nofollow&#34;&#62;http://chroniclingamerica.loc.gov/beta/&#60;/a&#62;
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>zachwhalen on "The right tool(s) for an archive of newspaper columns"</title>
						<link>http://digitalhumanities.org/answers/topic/the-right-tools-for-an-archive-of-newspaper-columns#post-1136</link>
			<pubDate>Fri, 22 Apr 2011 19:44:50 +0000</pubDate>
			<dc:creator>zachwhalen</dc:creator>
			<guid isPermaLink="false">1136@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Hi Folks,&#60;/p&#62;
&#60;p&#62;I'm considering a project that is more or less on my own time, and sort of in an area of inquiry that I don't often pursue. Therefore, I hope to get some input on the right toolset to get some work done.&#60;/p&#62;
&#60;p&#62;My great grandfather was a newspaper columnist, and his work is currently only available in microfilm and in moldy boxes at my grandmother's house. I would love to get this electronified, even if it's only for our family to use.&#60;/p&#62;
&#60;p&#62;Omeka seems like the logical choice for organizing and eventually conveying the archive, but what else can I use to 1) make this as painless as possible and 2) give me a rich set of data for interesting analysis and text mining?&#60;/p&#62;
&#60;p&#62;The stack of papers is pretty large -- we're looking at 35 years-worth of daily columns. The kinds of things I'd be interested in tracking would mostly be time-based (i.e. keyed to periods of time like presidencies or other historical events. &#60;/p&#62;
&#60;p&#62;I do have some help, in siblings and cousins, for transcriptions or other tedious work, but is there some OCR approach I should consider?&#60;/p&#62;
&#60;p&#62;This is very much in the &#34;Maybe we could do this ...&#34; phase, so I'd appreciate any thoughts or suggestions.&#60;/p&#62;
&#60;p&#62;Thanks,&#60;br /&#62;
Zach
&#60;/p&#62;</description>
		</item>

	</channel>
</rss>

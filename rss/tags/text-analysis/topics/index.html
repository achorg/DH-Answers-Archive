<?
/*
Plugin Name: bb Topic Icons
Plugin URI: http://devt.caffeinatedbliss.com/bbpress/topic-icons
Description: Adds configurable icons next to topics based on their status
Author: Paul Hawke
Author URI: http://paul.caffeinatedbliss.com/
Version: 0.6
*/

/****************************************************************************
 *
 * Configure the following constants to fine-tune the CSS classes that are
 * generated, the icon filenames that are used, and the text used in the
 * legend (if you have one displayed).  Note: filenames are likely to be
 * taken away in a future version and replaced with the concept of "icon sets"
 * whose filenames are fixed, so dont get used to editing the filenames,
 * as this will break in future versions.
 *
 ****************************************************************************/

// css class for the unsorted list used in the legend display
define( LEGEND_CLASS, 'topic_icon_legend' );

// busy threshold - a topic with more posts than this is counted as "busy"
// for purposes of picking an icon.
define( BUSY_THRESHOLD, 15 );

// width of the images, in pixels
define( ICON_WIDTH, '20' );

// height of the images, in pixels
define( ICON_HEIGHT, '20' );

// the URL base for where to find the default icon set.
define( ICON_SET_URL_BASE, BB_PLUGIN_URL.'bb-topic-icons/icon-sets/' );

/****************************************************************************
 *
 * Shouldnt be much need to edit anything beyond this point - configuration
 * is all done via the constants (above) and through and admin area page in
 * bbPress at runtime.
 *
 ****************************************************************************/

require( 'bb-topic-icons-api.php' );
require( 'bb-topic-icons-admin.php' );
require( 'interface.status-interpreter.php' );
require( 'interface.status-renderer.php' );
require( 'class.default-status-interpreter.php' );
require( 'class.default-status-renderer.php' );

function topic_icons_legend() {
	$icon_set_name = topic_icons_get_active_icon_set();
	$icon_set_url = ICON_SET_URL_BASE . $icon_set_name;
	$statuses = get_active_status_interpreter()->getAllStatuses();
	$renderer = get_active_status_renderer();
	
	echo '<ul id="'.LEGEND_CLASS.'">';
	for ($i=0; $i < count($statuses); $i++) {
		$image = $renderer->renderStatus($statuses[$i]);
		$tooltip = $renderer->renderStatusTooltip($statuses[$i]);
		$exists = file_exists(dirname(__FILE__).'/icon-sets/'.$icon_set_name.'/'.$image);

		if (isset($image) && strlen($image) > 0 &&
			isset($tooltip) && strlen($tooltip) > 0 && $exists) {
			echo '<li><img src="'.$icon_set_url.'/'.$image.
				'" width="'.ICON_WIDTH.'" height="'.ICON_HEIGHT.
				'" align="absmiddle">&nbsp;'.$tooltip.'</li>';
		}
	}
	echo '</ul>';
}

function topic_icons_css() {
	echo "\n<style type=\"text/css\"><!--\n";
	require( 'bb-topic-icons.css' );
	echo "\n--></style>";
}

function topic_icons_label( $label ) {
	global $topic;
	
	if (bb_is_front() || bb_is_forum() || bb_is_view() || bb_is_tag()) {		
		$icon_set_name = topic_icons_get_active_icon_set();
		$icon_set_url = ICON_SET_URL_BASE . $icon_set_name;

		$status = get_active_status_interpreter()->getStatus(bb_get_location(), $topic);
		$renderer = get_active_status_renderer();
		$image = $renderer->renderStatus($status);
		$tooltip = $renderer->renderStatusTooltip($status);
		$exists = file_exists(dirname(__FILE__).'/icon-sets/'.$icon_set_name.'/'.$image);

		if (!$exists) {
			return sprintf(__('<div class="topic-icon-image"><a href="%s"><img src="%s" width="%s" height="%s" alt="%s" border="0"></a></div> %s'), 
				get_topic_link($topic->topic_id), ICON_SET_URL_BASE.'/empty.png', ICON_WIDTH, ICON_HEIGHT, $tooltip, $label);
		} else if (strlen($tooltip) > 0) {		
			return sprintf(__('<div class="topic-icon-image"><a href="%s"><img src="%s" width="%s" height="%s" alt="%s" border="0"><span>%s</span></a></div> %s'), 
				get_topic_link($topic->topic_id), $icon_set_url.'/'.$image, ICON_WIDTH, ICON_HEIGHT, $tooltip, $tooltip, $label);
		} else {
			return sprintf(__('<div class="topic-icon-image"><a href="%s"><img src="%s" width="%s" height="%s" alt="%s" border="0"></a></div> %s'), 
				get_topic_link($topic->topic_id), $icon_set_url.'/'.$image, ICON_WIDTH, ICON_HEIGHT, $tooltip, $label);
		}
	}
	
	return $label;
}

function topic_icons_init( ) {
	remove_filter('bb_topic_labels', 'bb_closed_label', 10);
	remove_filter('bb_topic_labels', 'bb_sticky_label', 20);

	add_filter('bb_topic_labels', 'topic_icons_label', 11);

	add_action('bb_head', 'topic_icons_css');

	add_action('bb_admin_menu_generator', 'topic_icons_admin_page_add');
	add_action('bb_admin-header.php', 'topic_icons_admin_page_process');
	
	topic_icons_register_status_interpreter('default', new DefaultStatusInterpreter(BUSY_THRESHOLD));
	topic_icons_register_status_renderer('default', new DefaultStatusRenderer());
}

topic_icons_init();

?>
<?xml version="1.0" encoding="UTF-8"?>
<!-- generator="bbPress/1.0.2" -->
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Digital Humanities Questions &#38; Answers &#187; Tag: text analysis - Recent Topics</title>
		<link>http://digitalhumanities.org/answers/tags/text-analysis</link>
		<description>Digital Humanities Questions &amp; Answers &#187; Tag: text analysis - Recent Topics</description>
		<language>en-US</language>
		<pubDate>Sun, 24 Mar 2019 17:08:46 +0000</pubDate>
		<generator>http://bbpress.org/?v=1.0.2</generator>
		<textInput>
			<title><![CDATA[Search]]></title>
			<description><![CDATA[Search all topics from these forums.]]></description>
			<name>q</name>
			<link>http://digitalhumanities.org/answers/search.php</link>
		</textInput>
		<atom:link href="http://digitalhumanities.org/answers/rss/tags/text-analysis/topics" rel="self" type="application/rss+xml" />

		<item>
			 
				<title>ullyot on "Which novels to assign for seminar in algorithmic criticism / distant reading?"</title>
						<link>http://digitalhumanities.org/answers/topic/which-novels-to-assign-for-seminar-in-algorithmic-criticism-distant-reading#post-2327</link>
			<pubDate>Fri, 15 May 2015 17:29:58 +0000</pubDate>
			<dc:creator>ullyot</dc:creator>
			<guid isPermaLink="false">2327@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I’m designing the graduate seminar I’ll teach in the Department of English this fall (2015) on the subject of ‘Algorithmic Criticism,’ a title I took from the subtitle of Stephen Ramsay’s 2011 book, Reading Machines. It’s an introduction to computational text-analysis for students of literature, from word frequency to topic modelling.&#60;/p&#62;
&#60;p&#62;By the end of the course, students will be comfortable moving between close reading and distant reading, or what Matthew Jockers calls micro-, meso-, and macro-analysis. (Along with Ramsay’s book, Jockers’ 2013 study Macroanalysis and his 2014 guide to Text Analysis with R for Students of Literature will be required readings.)&#60;/p&#62;
&#60;p&#62;Students will learn and implement some programming basics using Python and R, so they can see what happens when natural-language processing and other tools parse and rearrange the words in both individual texts and larger corpora. I haven’t developed more detailed course outcomes than that. We’ll use Codecademy’s Python tutorials alongside Jockers’ book on R.&#60;/p&#62;
&#60;p&#62;So which literary texts do you assign for old-fashioned linear close readings in a course like this? They should be long enough to have a lot of words to work with, and complex enough that they contain a lot of topics. They should provide good contrasts with each other – that is, contain a lot of different words and topics – yet be close enough in time that the comparison makes sense. And they should be in the public domain, so we have texts to manipulate in whatever repository we’re drawing them from.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>aliciapeaker@gmail.com on "How to extract tagged data and text from TEI file?"</title>
						<link>http://digitalhumanities.org/answers/topic/how-to-extract-tagged-data-and-text-from-tei-file#post-2286</link>
			<pubDate>Thu, 26 Feb 2015 16:56:54 +0000</pubDate>
			<dc:creator>aliciapeaker@gmail.com</dc:creator>
			<guid isPermaLink="false">2286@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I’ve been using CATMA (&#60;a href=&#34;http://www.catma.de/&#34; rel=&#34;nofollow&#34;&#62;http://www.catma.de/&#60;/a&#62;) to markup a text with some analytical tags I’ve created. I then exported the file in TEI, and I’m now trying to extract the data I’ve marked up in order to measure tag frequencies, but am finding it quite difficult. &#60;/p&#62;
&#60;p&#62;Rather than tagging text with the labels I’ve created, CATMA has established a somewhat complicated (though likely necessary) system of identifiers. So, for example, I’ve tagged the word “clouds” in my text with the tag “weather,” which is a child of the tagset “non-living.” &#60;/p&#62;
&#60;p&#62;CATMA represents the tag in the text like this:&#60;br /&#62;
&#38;lt;text&#38;gt;&#60;br /&#62;
     &#38;lt;body&#38;gt;&#60;br /&#62;
          &#38;lt;ab type=“catma”&#38;gt;&#60;br /&#62;
Small feckless &#38;lt;seg ana=&#34;#CATMA_0036983F-4D37-48C2-8BC7-5846A8364D26&#34;&#38;gt;clouds&#38;lt;/seg&#38;gt; were hurried across the vast untroubled sky...&#60;br /&#62;
          &#38;lt;/ab&#38;gt;&#60;br /&#62;
     &#38;lt;/body&#38;gt;&#60;br /&#62;
&#38;lt;/text&#38;gt;&#60;/p&#62;
&#60;p&#62;The identifier then points to this feature statement after the body of the text:&#60;/p&#62;
&#60;p&#62;&#38;lt;text&#38;gt;&#60;br /&#62;
     &#38;lt;body&#38;gt;&#60;br /&#62;
     &#38;lt;/body&#38;gt;&#60;br /&#62;
          &#38;lt;fs xml:id=&#34;CATMA_0036983F-4D37-48C2-8BC7-5846A8364D26&#34; type=&#34;CATMA_3CDE1FE4-CA5D-4460-9BFF-739537D753DE&#34;&#38;gt;&#60;br /&#62;
            &#38;lt;f name=&#34;catma_displaycolor&#34;&#38;gt;&#60;br /&#62;
                &#38;lt;string&#38;gt;-16710765&#38;lt;/string&#38;gt;&#60;br /&#62;
            &#38;lt;/f&#38;gt;&#60;br /&#62;
            &#38;lt;f name=&#34;catma_markupauthor&#34;&#38;gt;&#60;br /&#62;
                &#38;lt;string&#38;gt;name@email&#38;lt;/string&#38;gt;&#60;br /&#62;
            &#38;lt;/f&#38;gt;&#60;br /&#62;
        &#38;lt;/fs&#38;gt;&#60;br /&#62;
&#38;lt;/text&#38;gt;&#60;/p&#62;
&#60;p&#62;The id for the type of the fs then points back up to the feature statement declaration in the header:&#60;/p&#62;
&#60;p&#62;&#38;lt;teiHeader&#38;gt;&#60;br /&#62;
     &#38;lt;encodingDesc&#38;gt;&#60;br /&#62;
          &#38;lt;fsDecl xml:id=&#34;CATMA_3CDE1FE4-CA5D-4460-9BFF-739537D753DE&#34; n=&#34;2014-12-16T13:30:36.000+0000&#34; type=&#34;CATMA_3CDE1FE4-CA5D-4460-9BFF-739537D753DE&#34;&#38;gt;&#60;br /&#62;
                    &#38;lt;fsDescr&#38;gt;Weather&#38;lt;/fsDescr&#38;gt;&#60;br /&#62;
                    &#38;lt;fDecl xml:id=&#34;CATMA_699BAC76-8D15-408E-A30A-984849115A71&#34; name=&#34;catma_displaycolor&#34;&#38;gt;&#60;br /&#62;
                        &#38;lt;vRange&#38;gt;&#60;br /&#62;
                            &#38;lt;vColl&#38;gt;&#60;br /&#62;
                                &#38;lt;string&#38;gt;-16710765&#38;lt;/string&#38;gt;&#60;br /&#62;
                            &#38;lt;/vColl&#38;gt;&#60;br /&#62;
                        &#38;lt;/vRange&#38;gt;&#60;br /&#62;
                    &#38;lt;/fDecl&#38;gt;&#60;br /&#62;
                    &#38;lt;fDecl xml:id=&#34;CATMA_8653855B-B611-48E8-AE9D-00E0160A37DB&#34; name=&#34;catma_markupauthor&#34;&#38;gt;&#60;br /&#62;
                        &#38;lt;vRange&#38;gt;&#60;br /&#62;
                            &#38;lt;vColl&#38;gt;&#60;br /&#62;
                                  &#38;lt;string&#38;gt;name@email&#38;lt;/string&#38;gt;&#60;br /&#62;
                            &#38;lt;/vColl&#38;gt;&#60;br /&#62;
                        &#38;lt;/vRange&#38;gt;&#60;br /&#62;
                    &#38;lt;/fDecl&#38;gt;&#60;br /&#62;
                &#38;lt;/fsDecl&#38;gt;&#60;br /&#62;
     &#38;lt;/encodingDesc&#38;gt;&#60;br /&#62;
&#38;lt;/teiHeader&#38;gt; &#60;/p&#62;
&#60;p&#62;I need to extract the text and data, perhaps in a csv file (or other output format, if it’s easier), into something that lists the tagged text (e.g. “clouds”) in one column, the first tag applied to it in the next column (e.g. &#34;weather&#34;), and the tagset or category to which that tag belongs in the next (e.g. &#34;non-living). &#60;/p&#62;
&#60;p&#62;Or perhaps there’s a better way—really, what I’d like to be able to do is get the frequencies of each tag &#38;amp; tagset for each chapter. If there’s an easier way to mark up the text in TEI that would better allow for what I need, I’m open to re-encoding manually.&#60;/p&#62;
&#60;p&#62;I’ve also tried playing around a bit with some XSLT and a Python script (&#60;a href=&#34;http://www.rdegges.com/quickly-extract-xml-data-with-python/&#34; rel=&#34;nofollow&#34;&#62;http://www.rdegges.com/quickly-extract-xml-data-with-python/&#60;/a&#62;) but with very little experience with either, I find myself quickly out of my depths. Open to suggestions—and thanks in advance for your help!
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>cforster on "Topic Modeling (MALLET) with JSTOR Data For Research"</title>
						<link>http://digitalhumanities.org/answers/topic/topic-modeling-mallet-with-jstor-data-for-research#post-1767</link>
			<pubDate>Mon, 29 Oct 2012 01:56:19 +0000</pubDate>
			<dc:creator>cforster</dc:creator>
			<guid isPermaLink="false">1767@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Does anyone have any experience using topic modeling to analyze data from JSTOR's &#60;a href=&#34;http://dfr.jstor.org/&#34;&#62;&#34;Data for Research&#34;&#60;/a&#62;? &#60;/p&#62;
&#60;p&#62;DFR lets you request datasets based on queries of the JSTOR database. Full-text of the JSTOR material, however, is not available. Instead one can request keywords, various ngrams (bi, tri, or quad), or word counts; requesting the word counts, one gets a set of files: one file per article with the word counts (CSV or XML), and a manifest (connecting filenames to complete[ish] citations). (Minor note: Looking at the raw counts, it seems like these may be samples of the articles, not the full word counts for the whole article, though I'm not totally sure; anyone have any experience with DFR?) &#60;/p&#62;
&#60;p&#62;My question: is there a way to get MALLET to take word counts as input rather than raw text? Since topic modeling treats texts/documents as bags of words, it should be able to work with the frequency counts as effectively as with raw text, right? I could write a script to reassemble texts in the proportions described by the word frequencies, but that seems so utterly absurd that I suspect (hope) I may be missing something.&#60;/p&#62;
&#60;p&#62;Anyone have any experience here?
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Josh on "How does one prepare and use data for network analysis with Gephi?"</title>
						<link>http://digitalhumanities.org/answers/topic/how-does-one-prepare-and-use-data-for-network-analysis-with-gephi#post-1880</link>
			<pubDate>Thu, 14 Feb 2013 16:09:22 +0000</pubDate>
			<dc:creator>Josh</dc:creator>
			<guid isPermaLink="false">1880@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;There are plenty of tutorials on the web that are useful for learning Gephi, but I've encountered a much steeper learning curve for the steps prior—such as extracting and preparing data from literary texts to be used with Gephi. In my example, I am interested in performing a network analysis of the social networks (both real and imaginary) in the works of Enrique Vila-Matas (I'd eventually like to expand this corpus to other authors). Acquiring the digital text and working with Gephi I can do (or the latter learn), but it's the very important intermediary steps of preparing the data (extraction of names and places to getting those in a form—database? spreadsheet?—analyzable by Gephi) that I need help with. Any good reading, tutorials, or other resources out there? Other recommendations? I'm working on a Mac and have a limited knowledge of Python, so any Mac-friendly software would be a big help. Thanks!
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Michael Widner on "Stopword list for Old English"</title>
						<link>http://digitalhumanities.org/answers/topic/stopword-list-for-old-english#post-1870</link>
			<pubDate>Fri, 01 Feb 2013 19:03:28 +0000</pubDate>
			<dc:creator>Michael Widner</dc:creator>
			<guid isPermaLink="false">1870@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I haven't been able to turn up an existing stop word list for Old English. Does anyone know of one? Thanks!
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>dot.porter on "Creating a wordlist from text"</title>
						<link>http://digitalhumanities.org/answers/topic/creating-a-wordlist-from-text#post-1753</link>
			<pubDate>Mon, 22 Oct 2012 14:26:48 +0000</pubDate>
			<dc:creator>dot.porter</dc:creator>
			<guid isPermaLink="false">1753@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I would like to create a list of words that are in a single long document. Having a word count included would be helpful, too.&#60;/p&#62;
&#60;p&#62;The purpose is to create a list of keywords that I can use to describe the items described in this document (it's a list of manuscript descriptions), with the eventual purpose of mapping those words to my own (very short) list of descriptors. But before I can map, I really need to know what words are used throughout the document.&#60;/p&#62;
&#60;p&#62;Is there a tool I might use to do this, or some XSLT or Perl script?
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Rosvita TEXTWinder on "Best way to map &#38; track debates through several little 1920s magazines?"</title>
						<link>http://digitalhumanities.org/answers/topic/best-way-to-map-track-debates-through-several-little-1920s-magazines#post-1610</link>
			<pubDate>Wed, 18 Apr 2012 15:28:25 +0000</pubDate>
			<dc:creator>Rosvita TEXTWinder</dc:creator>
			<guid isPermaLink="false">1610@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I'd like to map and track ideas that were debated in several little magazines of the 1920s to present a visualisation of where those &#34;conversations&#34; took place and how they changed with each contribution. It would be great to learn how others would approach this. Thanks!
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>JaneH-S on "Recommendations on ethnographic software?"</title>
						<link>http://digitalhumanities.org/answers/topic/recommendations-on-ethnographic-software#post-1560</link>
			<pubDate>Thu, 15 Mar 2012 13:54:15 +0000</pubDate>
			<dc:creator>JaneH-S</dc:creator>
			<guid isPermaLink="false">1560@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;We are looking for tools to tag and analyze interview transcript texts. Should work in tandem with archival/database software, undetermined as yet. Center on Aging and Community, Indiana University.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Lisa Rhody on "Does anyone have experience using the newest 3.5 Leximancer software?"</title>
						<link>http://digitalhumanities.org/answers/topic/does-anyone-have-experience-using-the-newest-35-leximancer-software#post-1397</link>
			<pubDate>Tue, 04 Oct 2011 12:12:52 +0000</pubDate>
			<dc:creator>Lisa Rhody</dc:creator>
			<guid isPermaLink="false">1397@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Leximancer (&#60;a href=&#34;https://www.leximancer.com)&#34; rel=&#34;nofollow&#34;&#62;https://www.leximancer.com)&#60;/a&#62;, an Australian, pay for use, text analysis software package seems intriguing.  It claims to be able to create topic and concept based network visualizations and includes among its filters a sentiment analyzer.  It's not cheap.&#60;/p&#62;
&#60;p&#62;If you do have experience with it?  Which type did you use?  The pay-per-use? The monthly portal? or the stand alone? Why?
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>cforster on "What have you discovered using the TEI and what programs did you use/create?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-have-you-discovered-using-the-tei-and-what-programs-did-you-usecreate#post-1169</link>
			<pubDate>Thu, 05 May 2011 14:49:59 +0000</pubDate>
			<dc:creator>cforster</dc:creator>
			<guid isPermaLink="false">1169@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;This question is really fascinating (especially since I suspect I have inkling of &#60;a href=&#34;http://dl.lib.brown.edu/mjp/&#34;&#62;the sort of texts&#60;/a&#62; you're interested in). Let me just dump a handful of links which I think might be helpful from my recent delicious/pinboard (hmm... delicious pinboard).&#60;/p&#62;
&#60;p&#62;While I can't point to specific results/papers. Aditi Muralidharan (@silverasm)'s WordSeer project is promising interesting results about slave narratives, though it does not rely on TEI. In &#60;a href=&#34;http://www.eecs.berkeley.edu/~aditi/projects/wordseer.html&#34;&#62;this talk&#60;/a&#62;, though, she does a good job of answering Sean's question directly--how can metadata improve on generic full-text search. WordSeer (as I understand it) works mostly by supplementing raw text with part of speech tagging and other grammatical metadata.&#60;/p&#62;
&#60;p&#62;With respect to TEI specifically one obvious place to start, I think, is &#60;a href=&#34;http://www.monkproject.org/&#34;&#62;MONK&#60;/a&#62;; as Dorothea notes, Martin Mueller is involved with the MONK project. You can find him summarizing MONK &#60;a href=&#34;http://www.cch.kcl.ac.uk/cocoon/tei2008/programme/abstracts/abstract-169.html&#34;&#62;here&#60;/a&#62; and at greater length &#60;a href=&#34;https://apps.lis.illinois.edu/wiki/display/MONK/Notes+towards+a+user+manual+of+Monk&#34;&#62;here&#60;/a&#62;. Unlike WordSeer, the Monk Workbench gives you metadata about author (including gender) and publication date. Matt Kirschenbaum mentions MONK in &#60;a href=&#34;http://www.cs.umbc.edu/~hillol/NGDM07/abstracts/talks/MKirschenbaum.pdf&#34;&#62;this article&#60;/a&#62; [PDF].&#60;/p&#62;
&#60;p&#62;(How relevant it will be to you, I don't know, but when I heard John Unsworth speak recently, he talked about the work flow and complications of large text collections with different encoding standards--with reference to MONK in particular. You can hear him &#60;a href=&#34;http://www.scholarslab.org/podcasts/unsworth-idiosyncrasy-at-scale/&#34;&#62;here&#60;/a&#62;.)&#60;/p&#62;
&#60;p&#62;There was a &#60;a href=&#34;http://listserv.brown.edu/archives/cgi-bin/wa?A1=ind1104&#38;amp;L=TEI-L&#38;amp;F=&#38;amp;S=&#38;amp;O=T&#38;amp;H=0&#38;amp;D=0&#38;amp;T=1#34&#34;&#62;recent discussion&#60;/a&#62; on the TEI list about eXist from which I learned a lot--again, about what's possible rather than specific results/reports.&#60;/p&#62;
&#60;p&#62;Finally--this one is also not TEI specific--if you haven't seen Ben Schmidt's blog, he is doing some pretty impressive stuff. This post, on &#60;a href=&#34;http://sappingattention.blogspot.com/2011/04/age-cohort-and-vocabulary-use.html&#34;&#62;vocabulary use and age cohort&#60;/a&#62; gives some idea.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>briancroxall on "What interfaces exist for working on scholarly resources housed in libraries?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-interfaces-exist-for-working-on-scholarly-resources-housed-in-libraries#post-1114</link>
			<pubDate>Wed, 06 Apr 2011 19:56:15 +0000</pubDate>
			<dc:creator>briancroxall</dc:creator>
			<guid isPermaLink="false">1114@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;At the Emory Libraries, we're considering a project to develop an interface to improve the usability for our &#60;a href=&#34;http://web.library.emory.edu/yellowbacks&#34;&#62;Yellowbacks collections&#60;/a&#62;. We would like to have an environment where scholars could do many different things: full-text searching, text analysis, multi-page comparison, annotations (that you can keep private or share), and more. Essentially, we're trying to let people do what they normally would to books, but with the books that aren't readily accessible or are in special collections&#60;/p&#62;
&#60;p&#62;Of course, we don't want to only build something that would be useful for one small collection. The interface we're envisioning would be something that could be used with much of our digital collections as well as the collections of other schools. But we're also aware that we're probably not the first to have this idea. We're currently conducting an environmental scan to make sure we can actually contribute something new or to identify those with whom we can collaborate.&#60;/p&#62;
&#60;p&#62;So, with that in mind, can you please tell me what interfaces already exist for working on scholarly resources housed in libraries?
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>donald on "suggested readings: text analysis of historical documents?"</title>
						<link>http://digitalhumanities.org/answers/topic/seeking-book-on-content-analysis-of-historical-letters#post-1083</link>
			<pubDate>Sat, 26 Mar 2011 17:43:33 +0000</pubDate>
			<dc:creator>donald</dc:creator>
			<guid isPermaLink="false">1083@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Hello everybody,&#60;/p&#62;
&#60;p&#62;I am seeking information on the use of Concordance and Linguistic Inquiry and Word Count software on American Civil War letters available at the Cook Center, Corsicana, Tx. I also would like to explore the Talbot Correspondence project online. Would anybody know of publications addressing content analysis of historical letters?&#60;/p&#62;
&#60;p&#62;all the best,&#60;/p&#62;
&#60;p&#62;donald wayne
&#60;/p&#62;</description>
		</item>

	</channel>
</rss>

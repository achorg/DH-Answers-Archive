<?xml version="1.0" encoding="UTF-8"?>
<!-- generator="bbPress/1.0.2" -->
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Digital Humanities Questions &#38; Answers &#187; Tag: text - Recent Posts</title>
		<link>http://digitalhumanities.org/answers/tags/text</link>
		<description>Digital Humanities Questions &amp; Answers &#187; Tag: text - Recent Posts</description>
		<language>en-US</language>
		<pubDate>Thu, 05 May 2016 04:26:14 +0000</pubDate>
		<generator>http://bbpress.org/?v=1.0.2</generator>
		<textInput>
			<title><![CDATA[Search]]></title>
			<description><![CDATA[Search all topics from these forums.]]></description>
			<name>q</name>
			<link>http://digitalhumanities.org/answers/search.php</link>
		</textInput>
		<atom:link href="http://digitalhumanities.org/answers/rss/tags/text" rel="self" type="application/rss+xml" />

		<item>
			 
				<title>Scott Weingart on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1993</link>
			<pubDate>Sun, 28 Apr 2013 23:09:18 +0000</pubDate>
			<dc:creator>Scott Weingart</dc:creator>
			<guid isPermaLink="false">1993@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/johnlaudun'&#62;johnlaudun&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1992&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;br /&#62;
Ah, sorry that I neglected to mention the header row! What you're seeing in the first picture is actually what you're looking for (a document-document network based on shared words), but the word nodes were not removed. Preprocessing-&#38;gt;Delete Isolates can do that. Also, if that was the bibliographic coupling, than the other algorithm will have the word-word network based on shared documents. As for getting the graph into gephi, try saving the network out as graphml, renaming the file from .xml to .graphml, and then loading it into gephi. &#60;/p&#62;
&#60;p&#62;In any case, because there are likely many words per document, you might do well to threshold above a certain value (filtering in gephi or preprocessing-&#38;gt;extract edges above or below value in sci2) to make the network a bit more sparse.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>johnlaudun on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1992</link>
			<pubDate>Sun, 28 Apr 2013 22:49:40 +0000</pubDate>
			<dc:creator>johnlaudun</dc:creator>
			<guid isPermaLink="false">1992@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Actually you said it quite well the first time:&#60;/p&#62;
&#60;blockquote&#62;&#60;p&#62;
once you have a csv with titles in one column and text in the second
&#60;/p&#62;&#60;/blockquote&#62;
&#60;p&#62;But apparently my reading comprehension is not up to par!&#60;/p&#62;
&#60;p&#62;Here's a brief summary of travails:&#60;/p&#62;
&#60;ul&#62;
&#60;li&#62; Sci2 expects CSVs to have a header row. This is important. It will not process the first row in a CSV and it will lead to awkwardly named outputs. (This took me a surprisingly long time to puzzle out.) &#60;/li&#62;
&#60;li&#62; I was glad to figure out the format of the file, because it also means I could potentially do my own stopwording, lemmatizing, etc. The menu item here is a wonderful one-stop shop, but I don't know that I always want everything it brings to the table.&#60;/li&#62;
&#60;li&#62; I got the directed network, no problem, but a visualization (using GUESS because I couldn't get the Gephi hand-off to work) reveals that the projection isn't really what one would expect:&#60;/li&#62;
&#60;/ul&#62;
&#60;p&#62;&#60;a href=&#34;http://www.flickr.com/photos/johnlaudun/8691631906/&#34; title=&#34;Screen Shot 2013-04-28 at 18.04.38 by johnlaudun, on Flickr&#34;&#62;&#38;lt;img src=&#34;http://farm8.staticflickr.com/7054/8691631906_8554b3905e_z.jpg&#34; width=&#34;640&#34; height=&#34;424&#34; alt=&#34;Screen Shot 2013-04-28 at 18.04.38&#34;&#38;gt;&#60;/a&#62;&#60;/p&#62;
&#60;p&#62;As I note on Flickr -- if this image makes it through -- what should have been either a word-to-word projection or a text-to-text projection based on a text-to-word CSV is in face a rather large visualization  in which the sixteen texts sit in a tight ball in the middle of an oort cloud of words.&#60;/p&#62;
&#60;p&#62;To be sure, I grabbed a screen capture of the Sci2 Data Manager pane, which does a lovely job of capturing at a glance what I had done:&#60;/p&#62;
&#60;p&#62;&#60;a href=&#34;http://www.flickr.com/photos/johnlaudun/8690511907/&#34; title=&#34;Screen Shot 2013-04-28 at 18.12.46 by johnlaudun, on Flickr&#34;&#62;&#38;lt;img src=&#34;http://farm8.staticflickr.com/7055/8690511907_c97c81dcc9_z.jpg&#34; width=&#34;501&#34; height=&#34;150&#34; alt=&#34;Screen Shot 2013-04-28 at 18.12.46&#34;&#38;gt;&#60;/a&#62;&#60;/p&#62;
&#60;p&#62;The CSV should work:&#60;/p&#62;
&#60;pre&#62;
TEXT,WORDS
ancelet-88,in&#124;charenton&#124;north&#124;o
ancelet-89,went&#124;meet&#124;old&#124;man&#124;ma
ancelet-90,mom&#124;said&#124;use&#124;dig&#124;lot
ancelet-91,know&#124;jess&#124;venabl&#124;fat
laudun-1,yeah&#124;s&#124;like&#124;talk&#124;shit&#124;
laudun-2,like&#124;said&#124;famili&#124;weird
&#60;/pre&#62;
&#60;p&#62;I'm going to keep playing with the various options to see what else might work. It's been a rough day -- also trying to get an 8 year old to step through a book presentation. That'll drive you nuts, right there.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Scott Weingart on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1989</link>
			<pubDate>Fri, 26 Apr 2013 15:23:56 +0000</pubDate>
			<dc:creator>Scott Weingart</dc:creator>
			<guid isPermaLink="false">1989@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/johnlaudun'&#62;johnlaudun&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1988&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;br /&#62;
I think maybe I didn't explain what I meant well enough the first time, sorry! If you have a csv that looks like &#60;/p&#62;
&#60;pre&#62;
title1, fulltext1
title2, fulltext2
title3, fulltext3
&#60;/pre&#62;
&#60;p&#62;Doing the steps I described above will get you &#60;/p&#62;
&#60;pre&#62;
t1, w1
t1, w2
t1, w3
t2, w1
t2, w3
t3, w2
t3, w3
t3, w4
&#60;/pre&#62;
&#60;p&#62;without any additional scripting. Hope it helps!
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>johnlaudun on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1988</link>
			<pubDate>Fri, 26 Apr 2013 15:19:09 +0000</pubDate>
			<dc:creator>johnlaudun</dc:creator>
			<guid isPermaLink="false">1988@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/johnlaudun'&#62;johnlaudun&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1987&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;/p&#62;
&#60;p&#62;What I'm working on is a script that goes from scraping out word frequencies to changing the csv to simply be the name-of-the-text, word, like this:&#60;/p&#62;
&#60;pre&#62;
    text1, word1
    text1, word2
    text1, word3
&#60;/pre&#62;
&#60;p&#62;I can then join those CSVs, to produce a CSV that looks like so:&#60;/p&#62;
&#60;pre&#62;
    t1, w1
    t1, w2
    t1, w3
    t2, w1
    t2, w3
    t3, w2
    t3, w3
    t3, w4

    and so on ...
&#60;/pre&#62;
&#60;p&#62;I'm going to try that out in Sci2.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>johnlaudun on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1987</link>
			<pubDate>Fri, 26 Apr 2013 14:52:15 +0000</pubDate>
			<dc:creator>johnlaudun</dc:creator>
			<guid isPermaLink="false">1987@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @Scott Weingart's &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1986&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;/p&#62;
&#60;p&#62;Hey, Scott, thanks for the replies. I will try them out, but first I have to get to the CSV of the bimodal network! Any ideas on how to get there from a collection of plain texts? It's this bit that has stumped me on a couple of occasions.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Scott Weingart on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1986</link>
			<pubDate>Fri, 26 Apr 2013 12:42:19 +0000</pubDate>
			<dc:creator>Scott Weingart</dc:creator>
			<guid isPermaLink="false">1986@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/johnlaudun'&#62;johnlaudun&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1984&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;br /&#62;
Also, on a side note, if you do the first normalization step and then &#34;Extract Word Co-Occurrence&#34; network, you can also get to words that co-occur frequently, as explained here: &#60;a href=&#34;http://wiki.cns.iu.edu/pages/viewpage.action?pageId=2200066#id-514StudyingFourMajorNetSciResearchersISIData-5145WordCo-OccurrenceNetwork5145WordCo-OccurrenceNetwork&#34; rel=&#34;nofollow&#34;&#62;http://wiki.cns.iu.edu/pages/viewpage.action?pageId=2200066#id-514StudyingFourMajorNetSciResearchersISIData-5145WordCo-OccurrenceNetwork5145WordCo-OccurrenceNetwork&#60;/a&#62;
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Scott Weingart on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1985</link>
			<pubDate>Fri, 26 Apr 2013 12:40:13 +0000</pubDate>
			<dc:creator>Scott Weingart</dc:creator>
			<guid isPermaLink="false">1985@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;&#60;em&#62;Replying to @&#60;a href='http://digitalhumanities.org/answers/profile/johnlaudun'&#62;johnlaudun&#60;/a&#62;'s &#60;a href=&#34;http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1984&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;&#60;br /&#62;
This can actually be done within Sci2 itself, once you have a csv with titles in one column and text in the second. Once that's loaded into Sci2, go to Preprocessing-&#38;gt;Topical-&#38;gt;Stopword Text (you can select your own stopword list from that dialog). &#60;/p&#62;
&#60;p&#62;Then go to Data Preparation-&#38;gt;Extract Directed Network, first column title, second column text, hit okay, and voila! You can then make that into texts based on words in common or words based on texts in common using either Data Prep-&#38;gt;Extract Co-Citation Network, or Extract Bibliographic Coupling Network (depending on your need), and you've got what you're looking for.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>johnlaudun on "Methods to process a plain text collection into a bimodal graph..."</title>
						<link>http://digitalhumanities.org/answers/topic/methods-to-process-a-plain-text-collection-into-a-bimodal-graph#post-1984</link>
			<pubDate>Fri, 26 Apr 2013 12:24:20 +0000</pubDate>
			<dc:creator>johnlaudun</dc:creator>
			<guid isPermaLink="false">1984@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I am starting a new project wherein I want to take a closer look at narratives both in terms of topics as well as in terms of morphologies. For the moment, I have narrowed my initial exploration to two collections of treasure legends, one drawn from oral sources (and transcribed by folklorists) and one drawn from materials found on on-line forums. Both collections are, purposefully as I take baby steps here, small: each is only sixteen texts. The texts range in size from 153 to 1025 words for the oral collection and 155-3081 words for the web collection. &#60;/p&#62;
&#60;p&#62;I am looking to create a bimodal graph for each of the collections which represents the relationship between the words used in each text, such that I can examine the relationship either between texts, based on words in common, or between words, based on texts in common.&#60;/p&#62;
&#60;p&#62;What I need, I think, is a Python script or some other kind of code/application which will work through each collection of plain text files and generate a CSV or network file of some kind that will let me then work in Gephi or Sci2. I would especially like it if the script would allow me to feed in a stopword list of my choosing.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Ge0ffrey on "How to Handle Soft Hyphens in OCR&#039;d PDF?"</title>
						<link>http://digitalhumanities.org/answers/topic/how-to-handle-soft-hyphens-in-ocrd-pdf#post-1673</link>
			<pubDate>Sat, 02 Jun 2012 20:23:45 +0000</pubDate>
			<dc:creator>Ge0ffrey</dc:creator>
			<guid isPermaLink="false">1673@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;There's a solution if you first import it into Word before turning it into a PDF.  First, highlight the soft hyphen and copy it.  Then, Control H (search and replace).  Paste the hyphen in the &#34;Find What&#34; box.  Replace it with a regular hyphen or some other sequence of characters, such as ***.  Then do a search and replace for the regular hyphen or the *** and replace it with nothing!  Et voila.  For some odd reason searching in Word for the ABBYYFine generated hyphen and replacing it with nothing doesn't work.&#60;/p&#62;
&#60;p&#62;&#60;em&#62;Replying to @Joe Wicentowski's &#60;a href=&#34;http://digitalhumanities.org/answers/topic/how-to-handle-soft-hyphens-in-ocrd-pdf#post-536&#34;&#62;post&#60;/a&#62;:&#60;/em&#62;
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>johnlaudun on "What should I read and what software should I use to do textual studies well?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-should-i-read-and-what-software-should-i-use-to-do-textual-studies-well#post-1315</link>
			<pubDate>Fri, 29 Jul 2011 17:59:42 +0000</pubDate>
			<dc:creator>johnlaudun</dc:creator>
			<guid isPermaLink="false">1315@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;It pains me to say it, but Rob is right, though I think some exposure to the command line is worth the time it takes. Something like Mallet is fairly advanced, but when I taught an intro to dh this past spring, I did get students to download IBM's word cloud Java app, which is command line only. The interesting side note to this is that students had to sign up with IBM's Developer Works in order to get the app, which also gives them access to the various pieces of Many Eyes, some of whose functionality is hard to replicate elsewhere -- as difficult as it sometimes is to get it to do what you want it to do.&#60;/p&#62;
&#60;p&#62;And that, I think, is sort of where we are right now. It often felt like I had a choice between teaching the ideas behind the various analytical possibilities or teaching the mechanics of the tools that could, but with no assurances that they would, realize those possibilities. I like the SEASR model very much, with its notion of graphical piping seeming to offer fairly advanced functionality with a very low entry threshold. &#60;/p&#62;
&#60;p&#62;The tools we ended up using most were Jim Dombrowski's Wordij and WordSmith. The down side to WordSmith is that it is proprietary (and it costs $) and it only runs in Windows. The upside is that you can get it to run over a network, and so you can use it across various labs and workstations on a campus; that it's fairly easy to use and for students to &#34;see&#34; results; and that it's popular among corpus linguists and others and so there are established protocols for using it.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>nelson.robert.k@gmail.com on "What should I read and what software should I use to do textual studies well?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-should-i-read-and-what-software-should-i-use-to-do-textual-studies-well#post-1314</link>
			<pubDate>Fri, 29 Jul 2011 09:33:37 +0000</pubDate>
			<dc:creator>nelson.robert.k@gmail.com</dc:creator>
			<guid isPermaLink="false">1314@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Brian, &#60;a href='http://mallet.cs.umass.edu/'&#62;MALLET&#60;/a&#62; would be useful for uncovering different thematic and topic threads and discovering words that are topically correlated to one another.  That said, as a command line tool with no GUI MALLET likely would be more challenging for your students to use than Voyeur and some of the other tools that have been mentioned already.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Stéfan Sinclair on "What should I read and what software should I use to do textual studies well?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-should-i-read-and-what-software-should-i-use-to-do-textual-studies-well#post-1313</link>
			<pubDate>Thu, 28 Jul 2011 21:49:07 +0000</pubDate>
			<dc:creator>Stéfan Sinclair</dc:creator>
			<guid isPermaLink="false">1313@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Sounds like fun Brian, but I'm *so* hurt that you didn't include &#60;a href=&#34;http://voyeurtools.org/&#34;&#62;Voyeur Tools&#60;/a&#62; in your preliminary list of text analysis tools to play with... :) You may also want to take a look that the accompanying documentation site on &#60;a href=&#34;http://hermeneuti.ca/voyeur&#34;&#62;Hermeneutica&#60;/a&#62;. Though less stable and not maintained, &#60;a href=&#34;http://hyperpo.org/&#34;&#62;HyperPo&#60;/a&#62; might also be worth a look.&#60;/p&#62;
&#60;p&#62;In addition to Katherine's great suggestions, check out Lisa Spiro's &#60;a href=&#34;https://digitalresearchtools.pbworks.com/w/page/17801672/FrontPage&#34;&#62;DiRT&#60;/a&#62;.&#60;/p&#62;
&#60;p&#62;Meagan Timney taught a course that may have some similarities to what you're doing, you may want to check out her list of &#60;a href=&#34;http://mdouglas.etcl.uvic.ca/huma150/resources&#34;&#62;resources and bibliography&#60;/a&#62; (especially the section on text analysis).&#60;/p&#62;
&#60;p&#62;I think it's useful to provide an example of using tools to do interesting things (not just descriptions and theorization of tools and text analysis generally). You might want to consider &#60;a href=&#34;http://llc.oxfordjournals.org/content/23/3/361.abstract&#34;&#62;Tanya Clements LLC article on Stein&#60;/a&#62;. A quicker example of rapid analysis (with tools) is something I wrote with Geoffrey Rockwell on the &#60;a href=&#34;http://hermeneuti.ca/rhetoric/now-analyze-that&#34;&#62;Barack Obama and Jeremiah Wright&#60;/a&#62; dust up during 2008 American elections.&#60;/p&#62;
&#60;p&#62;Everything I'm writing here makes me think of a dozen others I should mention, so maybe I should just stop there for now and let others chime in.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>katherineharris on "What should I read and what software should I use to do textual studies well?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-should-i-read-and-what-software-should-i-use-to-do-textual-studies-well#post-1312</link>
			<pubDate>Thu, 28 Jul 2011 16:25:06 +0000</pubDate>
			<dc:creator>katherineharris</dc:creator>
			<guid isPermaLink="false">1312@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Brian, I've used TaPoR for a few of my classes to offer data mining (&#60;a href=&#34;http://portal.tapor.ca/portal/portal&#34; rel=&#34;nofollow&#34;&#62;http://portal.tapor.ca/portal/portal&#60;/a&#62;) capabilities to, say, Heart of Darkness. We looked cursorily at the recurring use of elephant, tusk, ivory in the novel and were surprised to find that none of these are really prominently used, especially considering that the entire novel is based on the commodification of a living thing.  &#60;/p&#62;
&#60;p&#62;You might also think about using JUXTA to compare multiple version -- similar to a Hinman Collator (&#60;a href=&#34;http://www.juxtasoftware.org/)&#34; rel=&#34;nofollow&#34;&#62;http://www.juxtasoftware.org/)&#60;/a&#62;. MONK is another good one, but I haven't used it in class yet so I can't attest to its pedagogical efficacy (&#60;a href=&#34;http://gautam.lis.illinois.edu/monkmiddleware/public/index.html)&#34; rel=&#34;nofollow&#34;&#62;http://gautam.lis.illinois.edu/monkmiddleware/public/index.html)&#60;/a&#62;. TokenX is another great one for visualization (&#60;a href=&#34;http://jetson.unl.edu:8080/cocoon/tokenx/index.html?file=../xml/base.xml)&#34; rel=&#34;nofollow&#34;&#62;http://jetson.unl.edu:8080/cocoon/tokenx/index.html?file=../xml/base.xml)&#60;/a&#62;. &#60;/p&#62;
&#60;p&#62;Ok, in terms of readings about textual studies/scholarship, I find that undergraduates fair better when I just explain it to them. If they want to move further into textual scholarship, I have references for them. But reading the big, heavy stuff can be a bit daunting. McGann, Greetham (Textual Scholarship), Tanselle, etc, are the big guns. Might I suggest a book that's geared towards undergraduates and beginning graduate students? Erick Keleman's Textual Editing &#38;amp; Criticism: An Introduction is mighty fine for your purposes (&#60;a href=&#34;http://www.amazon.com/Textual-Editing-Criticism-Erick-Kelemen/dp/0393929426)&#34; rel=&#34;nofollow&#34;&#62;http://www.amazon.com/Textual-Editing-Criticism-Erick-Kelemen/dp/0393929426)&#60;/a&#62;. &#60;/p&#62;
&#60;p&#62;You might also take a look at my reading schedule for a Materials &#38;amp; Methods grad course that I taught a few years ago; some of the articles might be meaty enough for your purposes but not more than mouthful: &#60;a href=&#34;http://www.sjsu.edu/faculty/harris/ResearchMethods/Methods_Intro.htm#sch&#34; rel=&#34;nofollow&#34;&#62;http://www.sjsu.edu/faculty/harris/ResearchMethods/Methods_Intro.htm#sch&#60;/a&#62;&#60;/p&#62;
&#60;p&#62;It sounds like what you want to do is build a scholarly edition and then add in some scholarly assessments. We've been fighting a bit about this in the textual realms -- if a crowd-sourced digital edition is the way to go. Ray Siemens, et al. have been working on a format for this (dynamic social edition).  You might read through these two articles for help:&#60;/p&#62;
&#60;p&#62;Bertrand Gervais, &#34;Is There a Text on this Screen?&#34; A Companion to Digital Literary Studies&#60;br /&#62;
Ken Price, &#34;Electronic Scholarly Editions,&#34; A Companion to Digital Literary Studies&#60;/p&#62;
&#60;p&#62;Then you might see these about using tools:&#60;br /&#62;
The Babbage Engine&#60;br /&#62;
&#34;Where Computer Science and Cultural Studies Collide,&#34; Matthew Kirschenbaum&#60;br /&#62;
&#34;Literature to Infinity,&#34; Inside Higher Ed, Scott McLemee&#60;br /&#62;
&#34;Algorithmic Criticism,&#34; A Companion to Digital Literary Studies&#60;br /&#62;
, Stephen Ramsay&#60;br /&#62;
&#34;Quantitative Analysis and Literary Studies,&#34; A Companion to Digital Literary Studies, David Hoover&#60;br /&#62;
&#34;Literary Alzheimer’s,&#34; New York Times Magazine&#60;/p&#62;
&#60;p&#62;(These last two categories of suggestions are all available online &#38;amp; in my reading schedule for my DH Honors course from last Fall, 9/21 &#38;amp; 9/28: &#60;a href=&#34;http://www.sjsu.edu/faculty/harris/DigLit_F10/Schedule.htm&#34; rel=&#34;nofollow&#34;&#62;http://www.sjsu.edu/faculty/harris/DigLit_F10/Schedule.htm&#60;/a&#62;&#60;/p&#62;
&#60;p&#62;Two students and I are currently grappling with how to represent a Modernist artist's renderings of some Wilde poetry. We will probably go with Omeka, but we're intending to have this peer reviewed and live on our library servers as a piece of scholarship. (We'd also love to have the page turner plug-in from the Internet Archive but that might be a pipe dream with Omeka.)&#60;/p&#62;
&#60;p&#62;Bethany, Neil, Ray, Kirstyn, Whitney, Matt K., Steve R., et al might have better/more suggestions too. &#60;/p&#62;
&#60;p&#62;Lots of primers on how to create a scholarly edition exist, but I haven't found a really great introduction to building a digital scholarly edition just yet. Please let me know if you do! and please share with us your finalized syllabus.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>briancroxall on "What should I read and what software should I use to do textual studies well?"</title>
						<link>http://digitalhumanities.org/answers/topic/what-should-i-read-and-what-software-should-i-use-to-do-textual-studies-well#post-1311</link>
			<pubDate>Thu, 28 Jul 2011 15:58:22 +0000</pubDate>
			<dc:creator>briancroxall</dc:creator>
			<guid isPermaLink="false">1311@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;I'm super excited to be &#34;Introduction to Digital Humanities&#34; this fall. As I've been turning over the course in my mind, I've known that I've wanted to do one or more projects with the students, probably using our special collections, which tend to be quite strong in particular swaths of literature. This week I sat down with &#60;a href=&#34;http://twitter.com/#!/LizChaseMARBL&#34;&#62;Liz Chase&#60;/a&#62;, one of our special collections librarians, and brainstormed. We came up with a great project involving &#60;a href=&#34;http://findingaids.library.emory.edu/documents/duffy834/?keywords=duffy&#34;&#62;our holdings of Carol Ann Duffy's notebooks&#60;/a&#62;. In short, we want to do some comparisons between how she writes in her 1999 volume, &#60;a href=&#34;http://www.amazon.com/Worlds-Wife-Carol-Ann-Duffy/dp/057119995X/briacrox-20&#34;&#62;The World's Wife&#60;/a&#62;, and her previous volumes. We're interested in thematic material, vocabulary she uses, poetic styles, and so forth. But as I've been working to design the project, I've come to realize that the students' work (to say nothing of my teaching) will be improved by the inclusion of some readings on textual scholarship along these lines. &#60;strong&#62;But I don't know this field at all.&#60;/strong&#62;&#60;/p&#62;
&#60;p&#62;What's more, I've been trying to think about what sort of software we might most profitably use to help push our analysis after creating a dataset of the texts. I'm guessing we'll want to represent word counts, word clouds, line structures, and more. My first thought is &#60;a href=&#34;http://seasr.org/&#34;&#62;SEASR&#60;/a&#62;, but I'm not familiar with the tool and I'm not sure if it's overkill or underkill or totally off the mark. I can always use &#60;a href=&#34;http://www.wordle.net/&#34;&#62;Wordle&#60;/a&#62;, but I would like to have more options. And perhaps if I really knew this field of scholarship then it would be easier for me to know which tools I should be using.&#60;/p&#62;
&#60;p&#62;What I really need, then, is a suggestion of books or articles that I should read so that our class proceeds thoughtfully on the project with an understanding of what's been done in the past. Any tool suggestions would be welcome as well.
&#60;/p&#62;</description>
		</item>
		<item>
			 
				<title>Joe Wicentowski on "How to Handle Soft Hyphens in OCR&#039;d PDF?"</title>
						<link>http://digitalhumanities.org/answers/topic/how-to-handle-soft-hyphens-in-ocrd-pdf#post-536</link>
			<pubDate>Tue, 19 Oct 2010 23:21:49 +0000</pubDate>
			<dc:creator>Joe Wicentowski</dc:creator>
			<guid isPermaLink="false">536@http://digitalhumanities.org/answers/</guid>
			<description>&#60;p&#62;Sounds like this would be a good question to post to the ABBYY Finereader forums - perhaps they can help you disable the creation of the soft hyphens.  I just noticed this problem myself today when working with a PDF document that I OCRed with ABBYY and saved to MS Word.  Even in Word, I couldn't find &#38;amp; replace the soft hyphens away...
&#60;/p&#62;</description>
		</item>

	</channel>
</rss>
